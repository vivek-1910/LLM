# Logistic Regression

This folder contains the logistic regression classification model using scikit-learn.

## ğŸ“ Structure

```
LR/
â”œâ”€â”€ logistic_regression.py   # Logistic regression model
â””â”€â”€ results.png              # Visualization of results
```

## ğŸ“Š Model

### Logistic Regression
- **File**: `logistic_regression.py`
- **Task**: Predict wine quality (Good/Poor)
- **Dataset**: Wine Quality (178 real wine samples)
- **Algorithm**: Linear classifier with logistic function
- **Accuracy**: 100%
- **Interpretable**: Shows feature importance through coefficients

## ğŸ”§ Requirements

```bash
pip install -r ../requirements.txt
```

## ğŸš€ Run from Assignment Root

```bash
# Run logistic regression
python LR/logistic_regression.py

# Run all models
python run_all.py
```

## ğŸ“š Key Concepts

### Logistic Regression Model
- **Equation**: P(y=1|x) = 1 / (1 + e^(-(wÂ·x + b)))
- **Order**: 1st order polynomial (linear)
- **Optimization**: Maximum Likelihood Estimation

### Advantages of Logistic Regression
âœ… Simple and interpretable  
âœ… Fast to train  
âœ… Provides probability estimates  
âœ… No hyperparameters to tune  
âœ… Good baseline model  

### Disadvantages
âŒ Assumes linear relationship  
âŒ May underperform on complex non-linear patterns  
âŒ Less flexible than neural networks

### Feature Coefficients
- **Positive coefficient**: Feature increases probability of positive class
- **Negative coefficient**: Feature decreases probability
- **Magnitude**: Larger absolute value = stronger effect

### Performance Metrics
- **Accuracy**: Percentage of correct predictions
- **Precision**: Of predicted positive, how many are correct
- **Recall**: Of actual positive, how many we predicted
- **F1-Score**: Harmonic mean of precision and recall
- **ROC-AUC**: Area under ROC curve (discrimination ability)

## ğŸ”„ Comparison: Logistic Regression vs ANN

| Aspect | Logistic Regression | ANN |
|--------|-------------------|-----|
| Complexity | Simple, linear | Complex, non-linear |
| Training Time | <1 second | 30+ seconds |
| Interpretability | High (coefficients) | Low (black box) |
| Performance | Good on linear data | Excellent on complex data |
| Overfitting | Less likely | Needs regularization |
| Hyperparameters | None | Many |
